# Parametric Drawing Generator

> Transform natural language and voice prompts into mathematical parametric curves and rendered images using AI.

**Built for Cal Hacks 12.0** ğŸš€

![Architecture](https://img.shields.io/badge/Frontend-Next.js_16-black?logo=next.js)
![Backend](https://img.shields.io/badge/Backend-FastAPI-009688?logo=fastapi)
![AI](https://img.shields.io/badge/AI-Claude_Sonnet_4.5-8B5CF6)

---

## âœ¨ What It Does

Describe an image with **text** or **voice**, and watch AI generate it using parametric equations:

- ğŸ¨ **Natural Language to Math** - "Draw a butterfly" â†’ parametric curves
- ğŸ¤ **Voice Input Support** - Record or upload audio descriptions
- ğŸ”„ **Iterative Refinement** - AI self-improves drawings through multi-agent evaluation
- ğŸ¤– **Robot-Ready Output** - Generate programs for physical drawing robots
- ğŸ–¼ï¸ **Beautiful Visualization** - High-quality rendered images

---

## ğŸš€ Quick Start (Run the Full Application)

### Prerequisites

- **Python 3.11+** with pip
- **Node.js 18+** with npm
- **Anthropic API Key** ([Get one here](https://console.anthropic.com/))

### 1. Clone & Set Up Environment

```bash
# Clone the repository
git clone <repository-url>
cd CalHacks12

# Set up environment variables
cp .env.example .env
# Edit .env and add your ANTHROPIC_API_KEY
```

### 2. Install Dependencies

#### Backend:
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
cd ..
```

#### Frontend:
```bash
cd frontend
npm install
cd ..
```

### 3. Run the Application

**Option A: Two Terminal Windows (Recommended)**

Terminal 1 - Backend:
```bash
cd backend
source venv/bin/activate  # On Windows: venv\Scripts\activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Terminal 2 - Frontend:
```bash
cd frontend
npm run dev
```

**Option B: Using tmux (Advanced)**
```bash
# Start backend in background pane
tmux new-session -d -s calhacks 'cd backend && source venv/bin/activate && uvicorn app.main:app --reload'
# Start frontend in foreground
tmux split-window -h 'cd frontend && npm run dev'
tmux attach -t calhacks
```

### 4. Open Your Browser

- **Frontend**: http://localhost:3000
- **Backend API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health

### 5. Try It Out!

1. Type a prompt: `"Draw a spiral flower with 5 petals"`
2. Or record audio: Click the microphone button and describe your image
3. Hit **"Generate Drawing"**
4. Watch the AI create parametric equations and render your image!

---

## ğŸ“ Project Structure

```
CalHacks12/
â”œâ”€â”€ frontend/                    # Next.js web application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx            # Main page component
â”‚   â”‚   â””â”€â”€ api/draw/route.ts   # API proxy to backend
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ drawing-input.tsx   # Input form (text/voice)
â”‚   â”‚   â””â”€â”€ drawing-results.tsx # Results display
â”‚   â”œâ”€â”€ types/drawing.ts        # TypeScript interfaces
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                     # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py             # FastAPI application
â”‚   â”‚   â”œâ”€â”€ pipeline.py         # Main orchestration pipeline
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ claude_client.py    # Claude AI integration
â”‚   â”‚   â”œâ”€â”€ renderer_agent.py   # Image rendering
â”‚   â”‚   â”œâ”€â”€ evaluator_agent.py  # Quality evaluation
â”‚   â”‚   â””â”€â”€ utils_relative.py   # Robot coordinate transforms
â”‚   â”œâ”€â”€ static/                 # Generated images (runtime)
â”‚   â”œâ”€â”€ exports/                # Robot programs (runtime)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ tests/                       # Test suite
â”œâ”€â”€ .env.example                 # Environment template
â”œâ”€â”€ .env                         # Your secrets (git-ignored)
â””â”€â”€ README.md                    # This file
```

---

## ğŸ› ï¸ Development Setup

### Backend Setup

1. **Create virtual environment:**
   ```bash
   cd backend
   python -m venv venv
   source venv/bin/activate
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment variables** (in project root `.env`):
   ```bash
   # Required
   ANTHROPIC_API_KEY=sk-ant-...

   # Optional
   VAPI_API_KEY=your_vapi_key      # For voice transcription
   LETTA_API_KEY=your_letta_key    # For persistent memory
   PORT=8000                        # Backend port (default: 8000)
   ```

4. **Run backend:**
   ```bash
   # Development mode with auto-reload
   uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

   # Or use the provided script:
   bash scripts/run_server.sh
   ```

5. **Verify it's running:**
   - API: http://localhost:8000
   - Docs: http://localhost:8000/docs
   - Health: http://localhost:8000/health

### Frontend Setup

1. **Install dependencies:**
   ```bash
   cd frontend
   npm install
   ```

2. **Configure backend URL** (optional):

   Create `frontend/.env.local` if you need to change the backend URL:
   ```bash
   BACKEND_URL=http://localhost:8000
   ```

   **Default:** If not set, it uses `http://localhost:8000`

3. **Run frontend:**
   ```bash
   npm run dev
   ```

4. **Verify it's running:**
   - Frontend: http://localhost:3000

### Running Both Together

**Recommended workflow:**

1. Start backend first (wait for "Application startup complete")
2. Start frontend second
3. Frontend will automatically connect to backend at `http://localhost:8000`

**Troubleshooting Connection:**
- âœ… Backend running? Check http://localhost:8000/health
- âœ… Frontend running? Check http://localhost:3000
- âœ… CORS enabled? (Backend automatically allows all origins in dev mode)
- âœ… Ports not in use? Change with `--port` or `PORT` env var

---

## ğŸ¯ How to Use

### Text Input

1. Open http://localhost:3000
2. Type your prompt: `"Draw a heart shape"`
3. Optionally toggle "Use Letta Memory" for contextual awareness
4. Click **"Generate Drawing"**
5. View your image, parametric equations, and AI evaluation score!

### Voice Input

1. Click the **"Record Audio"** button (grant microphone permission)
2. Describe your image: *"Draw a butterfly with rainbow wings"*
3. Click **"Stop Recording"**
4. The system will transcribe and generate your drawing
5. See the transcribed prompt displayed with your image

**Or upload an audio file:**
1. Click **"Upload Audio"**
2. Select a .wav, .mp3, or other audio file
3. Generate!

---

## ğŸ—ï¸ Architecture

### System Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FRONTEND                             â”‚
â”‚  (Next.js 16 + React 19 + Tailwind CSS + shadcn/ui)       â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚ Text Input   â”‚      â”‚ Voice Input  â”‚                   â”‚
â”‚  â”‚  Component   â”‚      â”‚  Component   â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚         â”‚                     â”‚                            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                   â”‚                                        â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚         â”‚   API Route        â”‚                             â”‚
â”‚         â”‚  /api/draw         â”‚                             â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ HTTP POST
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BACKEND                             â”‚
â”‚            (FastAPI + Python 3.11)                       â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ POST /draw  â”‚         â”‚POST /draw/  â”‚                â”‚
â”‚  â”‚   (text)    â”‚         â”‚   audio     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚         â”‚                       â”‚                        â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚         â”‚    â”‚                                           â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”                                      â”‚
â”‚    â”‚   Pipeline   â”‚                                      â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚         â”‚                                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚  Phase 1: Prompt Interpretation       â”‚            â”‚
â”‚    â”‚           (Claude)                    â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚  Phase 2: Equation Generation         â”‚            â”‚
â”‚    â”‚           (Claude)                    â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚  Phase 3: Multi-Agent Refinement      â”‚            â”‚
â”‚    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚            â”‚
â”‚    â”‚   â”‚ Render â†’ Evaluate â†’    â”‚          â”‚            â”‚
â”‚    â”‚   â”‚ Refine (up to 3x)      â”‚          â”‚            â”‚
â”‚    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚  Phase 4: Relative Program Gen        â”‚            â”‚
â”‚    â”‚   (Robot coordinate transforms)       â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â”‚                                                â”‚
â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚    â”‚  Phase 5: Return Results              â”‚            â”‚
â”‚    â”‚  - Image (base64)                     â”‚            â”‚
â”‚    â”‚  - Parametric equations               â”‚            â”‚
â”‚    â”‚  - Robot program                      â”‚            â”‚
â”‚    â”‚  - Evaluation score                   â”‚            â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

**Frontend:**
- **Framework:** Next.js 16 (App Router) + React 19
- **Styling:** Tailwind CSS 4 + shadcn/ui components
- **Audio:** Web Audio API + MediaRecorder
- **Type Safety:** TypeScript 5

**Backend:**
- **Framework:** FastAPI (Python 3.11)
- **AI:** Anthropic Claude Sonnet 4.5
- **Rendering:** Matplotlib
- **Voice (Optional):** Vapi API
- **Memory (Optional):** Letta Cloud
- **Data Validation:** Pydantic v2

---

## ğŸ“¡ API Reference

### Frontend â†’ Backend Flow

#### Text Input Flow:
```
POST /api/draw
Content-Type: application/json

{
  "prompt": "Draw a circle",
  "use_letta": false
}
â†“
Backend: POST http://localhost:8000/draw
â†“
Response: DrawingResponse
```

#### Audio Input Flow:
```
POST /api/draw
Content-Type: multipart/form-data

FormData {
  file: Blob (audio),
  use_letta: "false"
}
â†“
Backend: POST http://localhost:8000/draw/audio
FormData {
  audio: Blob,
  use_letta: "false"
}
â†“
Response: DrawingResponse (with transcribed prompt)
```

### Backend Endpoints

**Full API documentation:** http://localhost:8000/docs

#### `POST /draw`
Create drawing from text prompt.

**Request:**
```json
{
  "prompt": "Draw a spiral galaxy",
  "use_letta": false
}
```

**Response:**
```json
{
  "success": true,
  "prompt": "Draw a spiral galaxy",
  "image_base64": "data:image/png;base64,...",
  "relative_program": {
    "segments": [
      {
        "name": "spiral_arm",
        "x_rel": "t*cos(t)",
        "y_rel": "t*sin(t)",
        "t_min": 0,
        "t_max": 12.566,
        "pen": { "color": "#000000" }
      }
    ]
  },
  "evaluation_score": 8.5,
  "iterations": 2,
  "processing_time": 4.2,
  "stats": {
    "run_id": "abc123...",
    "export_path": "exports/relative_program_abc123.json"
  }
}
```

#### `POST /draw/audio`
Create drawing from audio file.

**Request:**
```bash
curl -X POST http://localhost:8000/draw/audio \
  -F "audio=@recording.wav" \
  -F "use_letta=false"
```

**Response:** Same as `/draw`, with transcribed prompt

#### `GET /robot/{run_id}`
Fetch robot program for physical drawing.

**Response:**
```json
{
  "run_id": "abc123...",
  "prompt": "Draw a star",
  "relative_program": { ... }
}
```

#### `GET /health`
Check system status.

**Response:**
```json
{
  "status": "healthy",
  "services": {
    "anthropic_claude": "configured",
    "vapi_voice": "not_configured",
    "letta_memory": "not_configured"
  }
}
```

---

## ğŸ¨ Understanding the Output

### Generated Image
The AI creates a mathematical drawing rendered as a PNG image, displayed in the frontend.

### Prompt Display
Shows the exact prompt used (especially useful for voice input to confirm transcription).

### Parametric Equations
**Relative Program Segments** (preferred for robots):
```
spiral_arm:
  x(t) = t*cos(t)
  y(t) = t*sin(t)
  t âˆˆ [0.00, 12.57]
  Color: Black
```

Each segment is expressed in **local coordinates** relative to the previous segment's end position. Perfect for robots without global localization!

### Evaluation Score
AI scores the drawing from 0-10 based on how well it matches the prompt:
- **9-10:** Excellent match
- **7-8:** Good match
- **5-6:** Acceptable
- **<5:** Needs improvement

### Iterations
Number of refinement cycles the AI performed (max 3).

---

## ğŸ§ª Testing

### Backend Testing

```bash
cd backend
source venv/bin/activate

# Run all tests
python -m pytest tests/

# Test a specific prompt
python tests/test_sample_prompt.py "Draw a heart"

# Interactive mode
python tests/test_sample_prompt.py --interactive
```

### Frontend Testing

```bash
cd frontend
npm run build  # Ensure no build errors
npm run lint   # Check for linting issues
```

### End-to-End Testing

1. Start both backend and frontend
2. **Test Text Input:**
   - Enter: `"Draw a circle"`
   - Verify image appears
   - Check parametric equations displayed
   - Confirm score and iterations shown

3. **Test Voice Input:**
   - Click "Record Audio"
   - Say: *"Draw a flower with 5 petals"*
   - Stop recording
   - Verify transcription appears
   - Check drawing generated

4. **Test Error Handling:**
   - Stop backend
   - Try to generate a drawing
   - Verify user-friendly error message appears
   - Restart backend
   - Verify recovery

---

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the project root:

```bash
# === REQUIRED ===
ANTHROPIC_API_KEY=sk-ant-...

# === OPTIONAL ===
# Voice transcription (Vapi)
VAPI_API_KEY=your_vapi_key

# Persistent memory across sessions (Letta)
LETTA_API_KEY=your_letta_key

# Backend port
PORT=8000
```

### Frontend Configuration

Create `frontend/.env.local` (optional):

```bash
# Backend URL (default: http://localhost:8000)
BACKEND_URL=http://localhost:8000

# For production deployment:
# BACKEND_URL=https://your-backend.com
```

---

## ğŸ³ Docker Deployment

### Backend Only

```bash
cd backend
docker build -t parametric-drawing-backend .
docker run -d -p 8000:8000 \
  -e ANTHROPIC_API_KEY=sk-ant-... \
  parametric-drawing-backend
```

### Full Stack (docker-compose)

Create `docker-compose.yml`:

```yaml
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - ./backend/static:/app/static
      - ./backend/exports:/app/exports

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - BACKEND_URL=http://backend:8000
    depends_on:
      - backend
```

Run:
```bash
docker-compose up -d
```

---

## ğŸ¤– Robot Integration

The system generates **relative motion programs** for physical drawing robots.

### How It Works

1. Generate a drawing via `/draw` endpoint
2. Backend returns `stats.run_id` and exports program to `exports/`
3. Robot fetches program via `GET /robot/{run_id}`
4. Robot executes segments sequentially in local coordinates

### Example Robot Code

```python
import requests
import math

# 1. Generate drawing on server
response = requests.post("http://server:8000/draw",
                         json={"prompt": "Draw a star"})
data = response.json()
run_id = data["stats"]["run_id"]

# 2. On robot: Fetch program
program = requests.get(f"http://server:8000/robot/{run_id}").json()

# 3. Execute each segment
for segment in program["relative_program"]["segments"]:
    if segment["pen"]["color"] == "none":
        # Pen up - travel move
        move_without_drawing(segment)
    else:
        # Pen down - draw with specified color
        set_pen_color(segment["pen"]["color"])
        draw_parametric_curve(
            x_expr=segment["x_rel"],
            y_expr=segment["y_rel"],
            t_min=segment["t_min"],
            t_max=segment["t_max"]
        )
    # Local frame automatically resets to (0,0,0) for next segment
```

### Pen Colors (Normalized)

All colors are automatically mapped to:
- `"none"` - Pen up (no drawing)
- `"#000000"` - Black pen
- `"#0000FF"` - Blue pen

Perfect for dual-pen robot systems!

---

## ğŸ“š Example Prompts

| Prompt | Complexity | Expected Result |
|--------|-----------|-----------------|
| `"Draw a circle"` | â­ | Perfect circle |
| `"Draw a heart shape"` | â­â­ | Symmetric heart |
| `"Draw a butterfly with symmetric wings"` | â­â­â­ | Butterfly with mirrored wings |
| `"Draw a flower with 5 petals"` | â­â­â­ | 5-petal radial flower |
| `"Draw a spiral galaxy"` | â­â­â­â­ | Logarithmic spiral |
| `"Draw a Celtic knot"` | â­â­â­â­â­ | Intricate interwoven pattern |

---

## ğŸ› Troubleshooting

### Frontend won't connect to backend

**Symptom:** "Failed to generate drawing" error

**Solutions:**
1. âœ… Check backend is running: `curl http://localhost:8000/health`
2. âœ… Check `BACKEND_URL` in `frontend/.env.local` (default: `http://localhost:8000`)
3. âœ… Check CORS in backend logs (should allow all origins in dev)
4. âœ… Check browser console for network errors

### "ANTHROPIC_API_KEY not found"

**Solution:**
```bash
# Check .env file exists in project root
cat .env

# Should contain:
ANTHROPIC_API_KEY=sk-ant-...

# Restart backend after adding key
```

### Port Already in Use

**Symptom:** `Address already in use` error

**Solutions:**
```bash
# Find process using port 8000
lsof -i :8000
kill -9 <PID>

# Or use different port
uvicorn app.main:app --port 8001
```

### Microphone Access Denied

**Solution:**
1. Check browser permissions (URL bar â†’ lock icon â†’ permissions)
2. Allow microphone access
3. Refresh page

### "Module not found" errors

**Backend:**
```bash
cd backend
source venv/bin/activate
pip install -r requirements.txt
```

**Frontend:**
```bash
cd frontend
rm -rf node_modules package-lock.json
npm install
```

### Images not appearing

**Solution:**
1. Check `backend/static/` directory exists and is writable
2. Check backend logs for rendering errors
3. Verify image data in browser DevTools â†’ Network tab
4. Check console for image loading errors

---

## ğŸš€ Production Deployment

### Environment Setup

**Backend:**
- Set `ANTHROPIC_API_KEY` in production environment
- Use `gunicorn` or `uvicorn` with production settings
- Configure proper CORS origins (not wildcard)
- Set up HTTPS with reverse proxy (nginx/Caddy)

**Frontend:**
- Set `BACKEND_URL` to production backend URL
- Build with `npm run build`
- Serve with `npm start` or deploy to Vercel/Netlify

### Recommended Stack

- **Backend:** Railway, Render, Fly.io, or AWS ECS
- **Frontend:** Vercel, Netlify, or Cloudflare Pages
- **Storage:** Mount persistent volumes for `static/` and `exports/`

---

## ğŸ“ How It Works (Under the Hood)

### Phase 1: Prompt Interpretation
Claude Sonnet 4.5 analyzes your prompt to extract:
- Visual components (e.g., "wings", "body", "petals")
- Symmetry type (vertical, horizontal, radial, none)
- Complexity rating (1-5 scale)
- Detailed structural description

### Phase 2: Equation Generation
Claude generates mathematical parametric equations:
- `x(t)` and `y(t)` expressions using trig functions
- Parameter range `[t_min, t_max]`
- Color information

**Example (Circle):**
```json
{
  "name": "circle",
  "x": "cos(t)",
  "y": "sin(t)",
  "t_min": 0,
  "t_max": 6.283185307179586
}
```

### Phase 3: Multi-Agent Refinement
Iterative improvement loop (up to 3 iterations):

1. **Renderer Agent:** Plots equations using Matplotlib
2. **Evaluator Agent:** Scores image 0-10, provides feedback
3. **Refinement Agent:** Adjusts equations based on feedback
4. Repeat until score â‰¥ 9 or max iterations reached

### Phase 4: Relative Program Generation
Transforms absolute curves into robot-ready format:

1. **Compute End Poses:** Calculate (x, y, Î¸) at end of each curve
2. **Local Frame Transform:** Express each curve relative to previous end pose
3. **Pen Control:** Assign normalized colors (`"none"`, `"#000000"`, `"#0000FF"`)

**Mathematical Transform:**
```
[x_rel]   [cos(-Î¸)  -sin(-Î¸)] ([x(t)]   [x_prev])
[y_rel] = [sin(-Î¸)   cos(-Î¸)] ([y(t)] - [y_prev])
```

### Phase 5: Output
Returns comprehensive results:
- Rendered image (base64 PNG with data URI)
- Relative program (robot-ready segments)
- Evaluation score and feedback
- Processing metadata

---

## ğŸ“– Additional Resources

- **Backend API Docs:** http://localhost:8000/docs (when running)
- **Anthropic Claude:** https://www.anthropic.com/claude
- **Next.js Documentation:** https://nextjs.org/docs
- **FastAPI Documentation:** https://fastapi.tiangolo.com/

---

## ğŸ™ Acknowledgments

Built with technologies from **Cal Hacks 12.0** sponsors:
- [Anthropic](https://anthropic.com) - Claude Sonnet 4.5 AI
- [Vapi](https://vapi.ai) - Voice-to-text API
- [Letta](https://letta.com) - Persistent memory
- [Fetch.ai](https://fetch.ai) - Agent framework concepts
- [Composio](https://composio.dev) - Tool integration patterns

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details

---

## ğŸ¤ Contributing

This is a hackathon project, but contributions, suggestions, and feedback are welcome! Feel free to:
- Open issues for bugs or feature requests
- Submit pull requests
- Share your generated drawings!

---

## ğŸ’¬ Support

For questions or issues:
1. Check the [Troubleshooting](#-troubleshooting) section
2. Review backend logs: `tail -f backend/logs/app.log`
3. Open an issue on GitHub
4. Contact the development team

---

**Happy Drawing! ğŸ¨âœ¨**
